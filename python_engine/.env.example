# ============================================================================
# APPLICATION SETTINGS
# ============================================================================
APP_NAME="Aesthetiq Python Engine"
APP_VERSION="1.0.0"
DEBUG=true
LOG_LEVEL=INFO
LOG_FORMAT=console  # "console" for development, "json" for production

# ============================================================================
# API CONFIGURATION
# ============================================================================
API_V1_PREFIX=/api/v1
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173

# ============================================================================
# MongoDB
# ============================================================================
MONGODB_URI=mongodb+srv://<user>:<password>@<cluster>/<db>?retryWrites=true&w=majority
MONGO_URI=mongodb+srv://<user>:<password>@<cluster>/<db>?retryWrites=true&w=majority
MONGODB_DB_NAME=<db_name>
MONGODB_WARDROBE_COLLECTION=wardrobeitems
MONGODB_STYLE_PROFILES_COLLECTION=styleprofiles

# ============================================================================
# LLM API KEYS
# ============================================================================
# OpenAI
OPENAI_API_KEY=sk-your-openai-api-key-here
# LLM Configuration
OPENAI_MODEL=gpt-4o-mini  # gpt-4, gpt-4o, gpt-4o-mini, gpt-3.5-turbo, claude-3-5-sonnet-20241022, etc.

# ============================================================================
# LANGFUSE (LLM OBSERVABILITY)
# ============================================================================
LANGFUSE_SECRET_KEY = "sk-lf-your-secret-key"
LANGFUSE_PUBLIC_KEY = "pk-lf-your-public-key"
LANGFUSE_BASE_URL = "https://cloud.langfuse.com"

# ============================================================================
# SERVER CONFIGURATION
# ============================================================================
HOST=0.0.0.0
PORT=8000

# ============================================================================
# MICROSERVICES CONFIGURATION (Gateway)
# ============================================================================
# Internal service URLs (used by gateway to route requests)
FACE_ANALYSIS_URL=http://face_analysis:8001
CLOTHING_RECOMMENDER_URL=http://clothing_recommender:8002
EMBEDDING_SERVICE_URL=http://embedding_service:8004

# Gateway timeouts (in seconds) - lenient for agentic workflows
# ML_SERVICE_TIMEOUT=300.0   # Optional: ML requests via gateway
# LLM_SERVICE_TIMEOUT=600.0  # Optional: LLM/agent streaming via gateway

# ============================================================================
# EMBEDDING SERVICE
# ============================================================================
# MongoDB Vector Search (requires MongoDB Atlas)
USE_VECTOR_SEARCH=true  # Set to true when you create vector search index in Atlas

# ============================================================================
# ML SERVICE CONFIGURATION (Face Analysis)
# ============================================================================
# Device for ML inference: "cpu" or "cuda"
DEVICE=cpu
# Directory containing model weights
WEIGHTS_DIR=/app/weights

# ============================================================================
# Recommender Settings
# ============================================================================
RECOMMENDER_SEARCH_LIMIT=20
RECOMMENDER_MIN_RESULTS=3
RECOMMENDER_MAX_ITERATIONS=3

TAVILY_API_KEY=tvly-your-tavily-api-key
MCP_SERVERS_URL="http://localhost:8010"

GUARDRAIL_PROVIDERS=guardrails-ai
GUARDRAILS_AI_THRESHOLD=0.5

GOOGLE_API_KEY=your-google-api-key
GOOGLE_CX=your-google-cx

REPLICATE_API_TOKEN=r8_your-replicate-token